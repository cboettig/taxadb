---
title: "taxadb: A High-Performance Local Taxonomic Database Interface"
author:
  - name: "Kari Norman"
    affiliation: ucb
  - name: "Jorrit Poelen"
    affiliation: jorritt
  - name: "Scott Chamberlain"
    affiliation: ropensci      
  - name: "Carl Boettiger"
    affiliation: ucb, 1
address:
  - code: ucb
    address: "Dept of Environmental Science, Policy, and Management, University of California Berkeley, Berkeley CA 94720-3114, USA"
  - code: jorrit
    address: "Independent consultant, Oakland, CA, USA"
  - code: ropensci
    address: "The rOpenSci Project, University of California Berkeley, Berkeley CA 94720-3114, USA"
abstract: |
  A familiar and growing challenge in ecological and evolutionary research is that of reconciling scientific names of relevant taxa when combining data from separate sources. While this problem is already well understood and numerous naming authorities have been created to address the issue, most researchers lack a fast, consistent, and intuitive way to reconcile taxonomic names.  Here, we present `taxadb` R package to address this gap.  In contrast to existing tools, `taxadb` provides the following:  
  1) `taxadb` accesses established naming authorities to resolve synonyms, IDs, and hiearchical classification.  
  2) `taxadb` creates a local database, managed automatically from within R, that provides fast operations on millions of taxonomic names.  
  3) `taxadb` provides a consistent and intuitive data format.  
  4) `taxadb` is built on a simple, extensible and language agnostic design that can easily accomodiate new authorities.  
  
journal: "Methods in Ecology & Evolution"
date: "`r Sys.Date()`"
bibliography: refs.bib
layout: 3p
output: 
  rticles::elsevier_article:
    includes:
      in_header: preamble.tex
---

```{r message=FALSE, include = FALSE}
library(kableExtra)
library(magrittr)
library(tidyverse)
library(taxadb)

pkgconfig::set_config("dplyr::na_matches" = "never")

printtable <- function(df){
  df %>% 
    kableExtra::kable("latex", booktabs=T) %>% 
    kable_styling(full_width = F)
}
knitr::opts_chunk$set(cache=TRUE, message=FALSE, warning=FALSE)

# no sci notation integers pleases
options(scipen=999)

```



As ecologists and evolutionary biologists synthesize datasets across larger and larger assemblies of species, we face a continual challenge of reconciling taxonomic names.
How many species are in the combined data? Do the studies use the same names for the same species, or do they use different synonyms for the same species?
Failing to correct for such differences can lead to significant inflation of species counts and miss-aligned  datasets (Figure 1).
These challenges have become particularly acute as it becomes increasingly common for researchers to work across larger number and diversity of species in any given analysis, which may preclude the resources or substantative taxonomic expertise all clades needed to resolve scientific names [@Patterson2010].
While these issues have long been recognized in the literature [], and a growing number of databases and tools have emerged and grown over the past few decades [e.g. @itis; @ncbi; @col], it remains difficult to resolve taxonomic names to a common authority in a transparent, efficient, and automatable manner.
Here, we present an R package, `taxadb`, which seeks to address this gap.

Databases of taxonomic names such as the Integrated Taxonomic Information System [ITIS; @itis], the National Center for Biological Information's (NCBI) Taxonomy database, [@ncbi], the Catalogue of Life [COL; @col], and over one hundred other providers have sought to address these problems by providing expert-curated lists of accepted taxonomic names, synonyms, associated taxonomic rank, hierarchical classification, and scientific authority (e.g. author and date) establishing a scientific name.
The R language [@R] is widely used in ecology and evolution [@Lai2019] and the `taxize` package [@Chamberlain2013] has become a popular way R users to interact with naming providers and name resolution services.  `taxize` implements bindings to the web APIs (Application Programming Interface) hosted by many popular taxonomic name providers. Unfortunately, this means that functions in the `taxize` are impacted by several major drawbacks that are inherent in the implementation of these central API servers, such as:

- Queries require internet access at all times
- Queries are slow and inefficient to implement and perform; frequently requiring separate API calls for each taxonomic name
- The type of query is highly limited by the API design. For instance, it is impossible usually impossible to make queries across the entire corpus of names, such as "which accepted name has the most known synonyms?"
- Both query formats and responses differ substantially across different naming providers, making it difficult to apply a script designed for one provider to different provider.
- Most queries are not reproducible, as the results depend on the state of the central server (and potentially the quality of the internet connection).  Many names providers update the server data either continuously or at regular intervals, including both revising existing names and adding new names.  <!-- For instance, @predicts2014 observes that 2013 Catalogue of Life includes the genus "Notiophilus" in two separate families, contrary to the rules of nomenclature.  This error does not occur in the 2018 edition. -->

Instead of binding existing web APIs, `taxadb` is built around a set compressed text files following a consistent, standardized layout or schema (discussed below). These files are automatically downloaded and imported and stored on a local database by `taxadb`.  The largest of the taxonomic naming providers today contain under 6 million name records with uncompressed file sizes under a GB, and can be compressed to around 50 MB and downloaded in under a minute on a 1 MB/s connection.  In contrast, querying a single name over the web API, requiring the server to respond, execute the query, and serialize the response, can take several seconds. Thus it does not take many taxa before transferring the entire data set to query locally is more efficient.  Moreover, this local copy can be cached on the user's machine, requiring only the one-time setup and enabling offline use.

After installing the `taxadb` R package, users can create local copies of data from any of the providers using the `td_create()` function and specifying the provider abbreviation (see Table 1), or `all` to install all available providers:

```{r message = FALSE, warning=FALSE}
library(tidyverse)
library(taxadb)
```

```{r eval=FALSE, message=FALSE}
td_create("all")
```

<!--  Next 2 paragraphs should possibly be left to a manual, but are likely to be overlooked aspects there... -->
This one-time download will download and import local copies of the provider data. By default `taxadb` creates a MonetDBLite database instance [@monetdblite], a columnar-oriented relational database requiring no additional installation while also providing persistent disk-based storage, and data is stored in the appropriate location specified for applications by the operating sytstem [@rappdirs]. Users can customize this location, or opt for any alternative relational database backend by providing alternative arguments, though the default MonetDBLite system can be an order of magnitude faster than popular alternatives such as Postgres [@monetdblite].  `taxadb` will automatically handle opening, caching, and closing the MonetDBLite connection, but note that one limitation of MonetDBLite is the restriction against concurrent access: two separate R sessions on the same machine cannot both access the database at the same time. Users who need concurrent access from multiple sessions may wish to use a standalone MonetDB server or other database server instead.

All `taxadb` functions can also operate in one-time-use mode without first installing a standalone server.  If a function requests a provider which has not been installed, the relevant table can be downloaded and read directly into memory.  This requires sufficient memory be available to hold the entire table (typically 1-2 GB) and will only be cached for the R session.  This can be useful in special cases such as execution on remote servers where this will be faster than importing the data locally, or to allow other packages to use methods such as `get_ids()` internally without assuming users will have first created a local copy with `td_create()`. Specify `db=NULL` on any `taxadb` function to force this in-memory dispatch. 

Functions in `taxadb` are organized into several families: 

- database functions  `td_create()`, `td_connect()` and `taxa_tbl()`
- queries that return vectors: `get_ids()` and it's complement, `get_names()`,
- queries that filter the underlying taxonomic data frames: `by_name()`, `by_rank()`, `by_id()`, and `by_common()`,
- and helper utilities, such as `clean_names()`. 


## Taxonomic IDs

Taxonomic identifiers provide a fundamental abstraction which lies at the heart of managing taxonomic names.  For instance, by resolving scientific names to identifiers, we can idetnify which names are synonyms -- different scientific names used to describe the same species -- and which names are not recognized. Unmatched names may indicate an error in data entry or otherwise warrant further investigation. Taxon identifiers area also easily resolved to the original authority (scientific publication) establishing the name. (The historical practice of appending an author and year to a scientific name, e.g. *Poa annua ssp. annua* (Smith 1912), serves a valuable role in disambiguating different uses of the same name but can be notoriously harder to resolve to the appropriate reference, while variation in this convention creates many distinct versions of the same name [@Patterson2010]).  


These issues are best illustrated using a minimal example.  We'll consider the task of combining data on bird extinction risk as assessed by the IUCN [@iucn] with data on average adult biomass, as estimated in the Elton Traits v1.0 database [@elton-traits.]  To keep the example consise enough for for visual presentation we will focus on a subset involving just 10 species:

```{r}
trait_data <- read_tsv(system.file("extdata", "trait_data.tsv", package="taxadb"))
status_data <- read_tsv(system.file("extdata", "status_data.tsv", package="taxadb"))
```

```{r echo=FALSE, cache = FALSE}
status_data %>% printtable()
```

```{r echo = FALSE, cache = FALSE }
trait_data %>% printtable()
```


If we attempted to join these data directly on the species names provided by each table, we would find very little overlap, with only one species having both a body mass and an IUCN threat status resolved:

```{r}
joined <- full_join(trait_data, status_data, by = c("elton_name" = "redlist_name")) 
```


```{r echo = FALSE, cache = FALSE}
joined %>% tidyr::replace_na(list(category = "-")) %>% printtable() # "NA" looks like a category, "-" is clearer visually
```

If we first resolve names used in each data set into shared identifiers, (for instance, using the Catalogue of Life), we discover that there is far more overlap in the species coverage than we might have realized at first.  First, we just add an ID column to each table by looking up the Catalog of Life identifier for the name provided:

```{r}

traits <- trait_data %>% mutate(id = get_ids(elton_name, "col"))
status <- status_data %>% mutate(id = get_ids(redlist_name, "col"))
```

We can now join on the `id` column instead of names directly:

```{r}
joined <- full_join(traits, status, by = "id") 
```

```{r cache = FALSE, echo = FALSE}
## Just for pretty-printing
joined %>%  
  tidyr::replace_na(list(category = "-", elton_name = "-", redlist_name = "-")) %>%
  select(elton_name, redlist_name, mass, category, id) %>%
  printtable()
```


This results in many more matches, as different scientific names are recognized by the naming provider (Catalog of Life 2018 in this case), as *synonyms* for the same species, and thus resolve to the same taxonomic identifier.  While we have focused on a small example for visual clarity here, the `get_ids()` function in `taxadb` can quickly resolve hundreds of thousands of species names to unique identifiers, thanks to the performance of fast joins in a local MonetDBLite database.


\dummy{\Begin{tcolorbox}[title= Box 1: Taxonomic Identifiers and Synonyms, lower separated=false]}

`get_ids()` returns the `acceptedNameUsageID`, the identifier associated with the *accepted* name.  Some naming providers, such as ITIS and NCBI, provide taxonomic identifiers to both synonyms and accepted names.  Other providers, such as COL and GBIF, only provide identifiers for accepted names.  Common practice in Darwin Core archives is to provide an `acceptedNameUsageID` only for names which are synonyms, and otherwise to provide a `taxonID`.  For accepted names, the `acceptedNameUsageID` is then given as missing (`NA`), while for synonyms, the `taxonID` may be missing (`NA`).  In contrast, `taxadb` lists the `acceptedNameUsageID` for accepted names (where it matches the `taxonID`), as well as known synonyms.  This is semantically identical, but also more convenient for database interfaces, since it allows a name to mapped to it's accepted identifier (or an identifier to map to it's accepted name usage) without the additional logic.  For consistency, we will use the term "identifier" to mean the `acceptedNameUsageID` rather than the more ambiguous `taxonID` (which is undefined for synonyms listed by many providers), unless explicitly stated otherwise.

\End{tcolorbox}

## Unresolved names

Notice that one species name could not be resolved to a COL identifier.  This could indicate a data entry problem such as a misspelling of a name, but failure to resolve properly specified scientific names is not uncommon, as even large scale efforts like the Catalogue of Life are far from a comprehensive list of all published scientific names.  


Perhaps we can resolve this name against a different authority?  As it has an IUCN classification already, the IUCN naming provider seems a natural place to start.  We can use the `synonyms()` table to attempt to identify any other scientific names by which this species is known:

```{r}
synonyms("Scleroptila gutturalis", "iucn")
```

Note that one of these synonyms is recognized in COL, and in fact matches a COL identifier of *Francolinus levalliantoides*, 376.69 grams, in our data set.  

```{r}
synonyms("Scleroptila gutturalis", "iucn") %>% 
  pull(synonym) %>% 
  get_ids("col")
```



## Additional taxonomic information


```{r}
by_rank("Aves", rank="class", provider = "col") %>% head(5)
```




## Caution using synonyms

This process of walking synonyms between different providers should always be done with care.  Synonyms can arise for many reasons (see [@something] for discussion), and treating accepted names and known synonyms as equivalent or interchangable can quickly lead to innaccurate conclusions.  


An accepted name can have many synonyms:

```{r}
most_synonyms <- taxa_tbl("col") %>% count(acceptedNameUsageID, sort = TRUE)
most_synonyms
```

Here we see that some accepted identifiers, such as `COL:43082445`, are known by as many as 456 different synonyms!  `get_ids()` function seamlessly handles the resolution of all these synonyms to their accepted name usage identifier when they can be mapped to a single accepted name. 

This query uses the `taxa_tbl()` function to directly access the full taxonomic record in the MonetDBLite database.  This approach is fast and powerful, but note that we are restricted to using `dplyr` functions, which can be directly translated into SQL, for such queries to work successfully.  Though the result looks like a data frame, most base R operations will not work as expected:

```{r}
most_synonyms$n
```
Such queries are also not possible through the API or web interface to Catalogue of Life. To use custom R functions or functions from other packages we must first call the `dplyr` function `collect()` to return the table into R's memory.  This should be done with care as an unfiltered table may require several gigabytes of memory to load. 



Some synonyms may also be associated with more than one unique identifier.  This situation is more difficult, as it is impossible to know which accepted name should be used for such synonyms without more context.  The `get_ids()` function will thus return `NA` for any name that matches more than one identifier, just as it will return `NA` for a name that does not match any identifier at all.  Other functions in `taxadb` allow us to explore these names further.

Having access to a local database makes it easy to explore such issues as "identify all synonyms that resolve to more than one accepted scientific name ID", like so: 



```{r}
most_ambiguous <-
taxa_tbl("col") %>% 
  filter(taxonomicStatus != "accepted") %>% 
  select(scientificName, acceptedNameUsageID) %>% 
  distinct() %>% 
  count(scientificName, sort=TRUE) %>%
  filter(n > 1)
most_ambiguous
```
Here we see the name *Mabuya bistriata* is a synonym which may be associated with no fewer than 32 different accepted scientific names!







<!--
The motivation for an API-based approach is reasonable: (1) Web APIs are a ubiquitous standard of data exchange (2) make very minimal assumptions about the language, software, or hardware avaialable to the user, (3) users access a single centrally managed database that is maintained and upgraded by the provider, and (4) the provider can easily control access to the data, measure usage statistics, and enforce rate limits.  Many existing tools provide bindings of these APIs as functions to a specific language, including `taxize`, `tits`, `rotl`, `worms`, `redlist` and `wikitaxa` [@Chamberlain2013; @itis; @rotl; @worrms; @wikitaxa]
-->




Darwin Core schema.

### Supported providers



- the Integrated Taxonomic Information System [ITIS; @itis], original formed to standardize taxonomic name usage across many agencies in the United States federal government, 
- the National Center for Biological Information's (NCBI) Taxonomy database, [@ncbi]
- Catalogue of Life (COL) Annual Species list. (2018 version at present)
- Global Biodiversity Information Facility Taxonomic Backbone [GBIF; @gbif].  
- FishBase [@fishbase] taxonomic names
- SeaLifeBase [@sealifebase] taxonomic names
- Wikidata [@jorrit]
- Open Tree Taxonomy, OTT
- International Union for Conservation of Nature and Natural Resources (IUCN) Red list @iucn

Note that some of these providers are primarily syntheses of other existing naming providers.  For instance, COL is based in part on over 130 other name databases (<http://www.catalogueoflife.org/col/info/databases>), including ITIS, FishBase, and the IUCN Redlist.  However, these syntheses may lag behind the most recent versions of their member databases, which can create surprisingly large mismatches.  Because `taxadb` provides access to the different providers using a common format, we can quickly explore this.  For instance, here we count how many accepted names in ITIS can actually be found in COL (as either accepted names or known synonyms):

```{r}
# how many ITIS accepted species names are in COL?
itis_in_col <-
taxa_tbl("itis") %>%
  filter(taxonomicStatus == "accepted", taxonRank == "species") %>%
  select(scientificName) %>% 
  left_join(taxa_tbl("col"), by="scientificName") %>% 
  filter(is.na(acceptedNameUsageID)) %>% 
  count() %>%
  pull(n)

# out of how many total accepted names in ITIS?
itis_accepted <- taxa_tbl("itis") %>%
  filter(taxonomicStatus == "accepted", taxonRank == "species") %>% 
  count() %>% pull(n)
```
$`r prettyNum(itis_in_col, big.mark = ",")`$ of the $`r prettyNum(itis_accepted, big.mark = ",")`$ of *accepted names* in ITIS ($`r round(itis_in_col / itis_accepted * 100)`$%) are not recognized by the (2018) Catalogue of Life as either accepted names or known synonyms. 

Consequently, just because the naming providers such as COL, OTT, and GBIF consume the names in ITIS, NCBI, or IUCN, this does not mean we can rely exclusively on these larger syntheses.  


<!--
It is important to distinguish between two broad kinds of naming providers.  Efforts such as ITIS, NCBI, FishBase, and SeaLifeBase are largely independent naming assemblies. GBIF and OTT are synthetic 'taxonomic backbones,' created by reconciling species names from a wide range of providers to create a taxonomic backbone utilized internally for their respective efforts.  Catalogue of Life (COL)
-->





<!--
comment that taxonomic backbones aren't really the same thing:
In addition to these projects, large biodiversity informatics efforts such as the Global Biodiversity Information Facility [GBIF; @gbif], publish the 'taxonomic backbone' -->



## Discussion

- Resolve names to identifiers
- Resolve synonyms to accepted names
- Associate names with taxonomic rank and heirarchical classification

discuss use Scientific names vs identifiers.  taxonConcepts?



- `taxadb` is not intended as an improvement or replacement for any existing approaches to taxonomic name resolution. Instead, it fills an important gap between existing tools and typical research patterns.  In particular, `taxadb` is not a replacement for the APIs or databases provided, but merely an interface to taxonomic naming information contained within that data. 

- `taxadb` works from versioned snapshots of the data providers. 

- All `taxadb` functions are specific to a provider, while operating consistently across different providers.  

- `taxadb` does not attempt to present any unified taxonomic backbone or synthesis from existing naming providers, or make any assertions, numerical scores or other inferences about the data or matches to the data -- it is merely a tool for accessing this infromation.  This contrasts from other approaches such as the Global Names Resolver, which 




There is an important objection to this approach that must also be addressed.  

@Franz2018 

>>  no self-respecting biodiversity researcher would or should trust aggregated data blindly, that indeed careful data cleaning is almost always necessary and expected to render the downloaded data fit for purpose, and that therefore aggregator services need to be understood mainly or merely as data discovery tools.

> We reject this deflationary view for four reasons. For one, aggregators frequently blur the lines between advertizing their services just as a data discovery tool or as a more powerful data signal tool. Second, the biases inherent in using unitary backbones remain in place even if users are only interested in discovering all relevant data for their research purpose. If the backbone-based data record modulations are not easily retrievable through primary on-line interfaces, then users are significantly constrained in their ability to design search queries with high rates of precision and recall (81). Third, let us assume that labor-intensive off-line data quality review and correction efforts are indeed the norm, prior to publishing. Then why must the fruits of these efforts remain outside of the aggregator’s environment? Why can they not immediately flow back into the same aggregation domain, while recording the provenance of expert changes? In other words, if the workflow of rendering data fit for purpose flows only in one direction, i.e. from the on-line aggregate to the off-line quality review and publication, then our criticism of the design stands.

The inability to make automate use and manipulation 

(Figure 1: schematic example of data join?)


Assemble data across multiple studies 

How many species of Chameleons are known? There are over 


```{r}
taxa_tbl("col") %>% count(taxonomicStatus, sort = TRUE)
```

----

\pagebreak

# References
